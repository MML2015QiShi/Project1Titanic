{
 "metadata": {
  "name": "",
  "signature": "sha256:e2bb4814e116bdfd02dac77dbeaf7aba270634ac24cf2b549dc1f7c75b5b6da2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Titanic: Machine Learning from Disasters III"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yiyang Yang"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This week, tree based model and ensemble method will be used to train models for predicting survival on titanic. The predicted results will be submitted to Kaggle for tests."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Decision Tree"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Decision tree will be used to classify passengers, based on Pclass, Sex, Age."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import tree\n",
      "\n",
      "df_train = pd.read_csv('train.csv',header=0)\n",
      "df_test = pd.read_csv('test.csv',header=0)\n",
      "\n",
      "Y1 = df_train.Survived.values\n",
      "age_grouped = df_train.groupby(['Pclass','Sex'])['Age'].median()\n",
      "subgroup = {1:'1F',2:'1M',3:'2F',4:'2M',5:'3F',6:'3M'}\n",
      "\n",
      "for i in range(1,7):\n",
      "    df_train[subgroup[i]] = 0\n",
      "    df_test[subgroup[i]] = 0\n",
      "    \n",
      "index = 1\n",
      "for c in range(1,4):\n",
      "    for s in ['female','male']:\n",
      "        df_train.Age[(df_train.Age.isnull()) \n",
      "                 & (df_train.Pclass == c)\n",
      "                 & (df_train.Sex == s)] = age_grouped[c][s]\n",
      "        df_test.Age[(df_test.Age.isnull()) \n",
      "                 & (df_test.Pclass == c)\n",
      "                 & (df_test.Sex == s)] = age_grouped[c][s]\n",
      "        print index, subgroup[index]\n",
      "        df_train[subgroup[index]][(df_train.Pclass == c)\n",
      "                 & (df_train.Sex == s)] = 1\n",
      "        df_test[subgroup[index]] [(df_test.Pclass == c)\n",
      "                 & (df_test.Sex == s)] = 1\n",
      "        index += 1\n",
      "        \n",
      "X1 = df_train[['1F','1M','2F','2M','3F','3M','Age']]\n",
      "X2 = df_test[['1F','1M','2F','2M','3F','3M','Age']]\n",
      "\n",
      "dtree = tree.DecisionTreeClassifier()\n",
      "dtree.fit(X1,Y1)\n",
      "p_Y1 = dtree.predict(X1)\n",
      "app = pd.Series(p_Y1==Y1)\n",
      "tmp = app.value_counts()\n",
      "print tmp\n",
      "print 'Accuracy of prediction for training set '+repr(tmp[True]*1.0/(tmp[True]+tmp[False]))\n",
      "df_test['Survived'] = dtree.predict(X2)\n",
      "df_test[['PassengerId','Survived']].to_csv('decisiontree.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 1F\n",
        "2 1M\n",
        "3 2F\n",
        "4 2M\n",
        "5 3F\n",
        "6 3M\n",
        "True     784\n",
        "False    107\n",
        "dtype: int64\n",
        "Accuracy of prediction for training set 0.87991021324354657\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This submission scored 0.70813. The decision tree model will have extremely high accuracy if there are more features included. In the above case, if more features are included, the accuracy of training data can be more than 0.9. However, the accuracy of test data will be much lower due to overfitting."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ensemble Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic regression is a typical model in classification. The linear regression model in scikit package is used to realize this function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "df_train = pd.read_csv('train.csv',header=0)\n",
      "df_test = pd.read_csv('test.csv',header=0)\n",
      "\n",
      "Y1 = df_train.Survived.values\n",
      "age_grouped = df_train.groupby(['Pclass','Sex'])['Age'].median()\n",
      "subgroup = {1:'1F',2:'1M',3:'2F',4:'2M',5:'3F',6:'3M'}\n",
      "\n",
      "for i in range(1,7):\n",
      "    df_train[subgroup[i]] = 0\n",
      "    df_test[subgroup[i]] = 0\n",
      "    \n",
      "index = 1\n",
      "for c in range(1,4):\n",
      "    for s in ['female','male']:\n",
      "        df_train.Age[(df_train.Age.isnull()) \n",
      "                 & (df_train.Pclass == c)\n",
      "                 & (df_train.Sex == s)] = age_grouped[c][s]\n",
      "        df_test.Age[(df_test.Age.isnull()) \n",
      "                 & (df_test.Pclass == c)\n",
      "                 & (df_test.Sex == s)] = age_grouped[c][s]\n",
      "        print index, subgroup[index]\n",
      "        df_train[subgroup[index]][(df_train.Pclass == c)\n",
      "                 & (df_train.Sex == s)] = 1\n",
      "        df_test[subgroup[index]] [(df_test.Pclass == c)\n",
      "                 & (df_test.Sex == s)] = 1\n",
      "        index += 1\n",
      "        \n",
      "X1 = df_train[['1F','1M','2F','2M','3F','3M','Age']]\n",
      "X2 = df_test[['1F','1M','2F','2M','3F','3M','Age']]\n",
      "\n",
      "gradboost = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X1,Y1)\n",
      "p_Y1 = gradboost.predict(X1)\n",
      "app = pd.Series(p_Y1==Y1)\n",
      "tmp = app.value_counts()\n",
      "print tmp\n",
      "print 'Accuracy of prediction for training set '+repr(tmp[True]*1.0/(tmp[True]+tmp[False]))\n",
      "df_test['Survived'] = gradboost.predict(X2)\n",
      "df_test[['PassengerId','Survived']].to_csv('gradientboost.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 1F\n",
        "2 1M\n",
        "3 2F\n",
        "4 2M\n",
        "5 3F\n",
        "6 3M\n",
        "True     741\n",
        "False    150\n",
        "dtype: int64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy of prediction for training set 0.83164983164983164\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The submission scored 0.72249. This result is better than decision tree, but worse than gender model, logistic regression and support vector machine."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After all these tryings, gender model is proved to be the most accurate. No model has scored more than 0.8 in submission. Over fitting is a potential problem for tree based methods which should be used with caution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}